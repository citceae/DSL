workflow:
1）生成训练程序。在训练集上用已有的程序合成求解器求解出大量的源语言上的
训练程序。本文中使用基于空间表示的程序合成求解器 MaxFlash 生成字符串处
理领域的训练程序。本文所使用的源语言是一个用于求解字符串处理问题的、
用上下文无关文法表达的、强类型的领域特定语言。
2）在训练程序上挖掘程序结构信息。包括训练程序中常见的模式、语法组件出现
的频率等。本文使用了频繁子树挖掘的方法挖掘训练程序中的常见模式。
3）将上一步挖掘到的程序结构抽象成语法上的修改操作，这些操作主要包含添加
语法组件、删除语法组件、对语法组件加以展开深度限制等。
4）利用搜索算法，找到一个由一系列修改操作组成的集合，使经过这些操作修改
的新语法相较源语言更优。本文方法的搜索过程分为两部分，首先使用估计函
数和遗传算法粗粒度地筛选出新语言的若干候选，再用直接测量求解时间的方
法在候选语言中选出最优的一个

TODO：
1.频繁子树挖掘算法
 1.1.将训练程序编码为前序树 done
 1.2.在前序树上进行频繁模式挖掘 done
2.抽象成修改操作
 2.1.添加根据频繁子树
 2.2.删除：统计频率删除某个阈值以下
 2.3.统计最大深度
3.估计函数和遗传算法
 3.1.编码修改操作生成对应的DSL half done
 3.2.对一个DSL计算适应度 适应度计算根据适应度函数有一些需要快速获取的信息 如按照枚举顺序目标程序的排序和删除了多少

1.1 编码方式 识别操作符和常量（编码成固定编号） 构造对应前序树
输入为多个解的字符串表示 输出为前序树（done）
1.2 频繁模式挖掘 利用github找到的一个CCtreeminer库（done）
https://github.com/zakimjz/SLEUTH
1left:收集多个解 多个训练任务 每个任务的多个解

2.1.需要去除一些参数（或者应该把参数都抽象成同一个如para0），主要挖掘的是操作符和操作符，操作符和常量之间组合得到的频繁模式（而且只拿到子树需要填充缺失的节点） 展示
 已有的result.txt里可以找到如 + 1 para1 但是更明显的可能需要把para1位置更改成统一的某个量 TODO
2.2.
2.3.根据得到的多个解 统计操作符的使用次数和终结符的最大深度 限深（？这个应该只加在非终结符上 如SLIA里就只有ntstring ntint ntbool三个终结符需要考虑深度？）
2left与1相同 拿到训练集对应的多个解后即可（训练集样本大小？多个训练程序*每个k个解）


3.得到设定好的基因集合 共有L中增加，删除，限制深度操作后 L位的基因
 3.1根据基因生成对应的DSL（base.sl） p.s.如果start不相同 需要生成多个版本的base.sl （给定基因，生成对应的base.sl 小的demo done）
 根据base.sl对测试集的每个DSL生成对应的修改了常量参量版本的DSL TODO（裁剪之后填充常量参量应该也是ok的）
 3.2对DSL计算适应度 
 主要需要Num(n_i)即每个训练问题上最小的解在新文法上的排序
 3.3整体遗传算法框架
 
 
 TODO：
 利用改动后的maxflash对benchmark每一个给出一堆解 done
 把一堆解读取成前序树 注意string和int的抽象 提取公共子树 done
 删除的频率如何统计（或者每个都可能删除用评估函数鉴别）
 限制深度（看微信图片整理的结果） 除了整体的深度还有左右子树的深度
 
 排序算法一脸懵
 1.先找到有没有目标程序（目标程序可以有100个）
 2.有compose之后不枚举的话怎么排序 程序的大小不是终结符的数量 而是使用的产生式的个数（？ntstring->"sss"规模会+1吗 如getprefix "SSDSS" 3 一共用了ntstring->getprefix ntstring ntint ntstring->"SSDSS" ntint->3 三条规则 最后的规模判断是1还是3？）
 3.compose之后 新compose的operator需要对应回原有的目标程序才能够得到排序上升的结果
 
直接枚举出每一个size的结果 单独增量式 对一个语法做一次枚举 而不是基于原来的语法对应一个原来的排序做的修改后快速定位
直接利用朴素枚举的框架？/obe去掉obe部分（如果时间开销主要是在验证反例上的话 可以把接口修改为找到一个集合(也就是枚举得到的100个解)里的一个程序 可以直接字符匹配）

对一个问题保证有一个解就好了吧 ooplsa里写的是保留所有解
保留所有解作排序分数也可以（目标是2900个程序都保留在空间内） 对每个修改后的DSL搜这2900个好像太heavy了...

维护一个DSL->prog 从小到大排序的集合
对一个新的DSL 寻找已有的与它“接近”的DSL 取用对应的prog并修改（去掉没有了的加上新的 怎么在对应大小的位置加上新的？）
或者对所有DSL的超集做一次排序 每次在这个基础上去掉不符合的

1.15
之前按照论文里3次以上的频次把系统跑崩了...
频繁模式的挖掘得到的是不确定占位符在哪里的 可能更好的挖掘手段是把占位符都填上的
indexof 0是什么作用
+ -1 和 - 1怎么ban掉
先整理了一下目前400以上的 还没有完全自动化

1.频繁模式挖掘 half done
2.删除（所有都可能删？或者根据2900个程序统计个频次 可做）
3.限制深度（限制深度硕士论文里只提到了非终结符的 投稿里提到了展开式的上下文也限制深度 根据2900个程序的产生式各自计算每个产生式的subterm的深度）
4.根据基因生成对应的DSL（按之前说法需要生成多个 根据start的不同 主要因为限制深度是提前的展开剪枝） 之前写过一些需要继续
5.根据DSL做适应度评估 NUM_i 删除的项的数目D 增加的项的数目A 让多少问题变得不可解（可以限定死 一个都不能少）
 5.1.NUM_i 按照论文里的说法其实不是什么增量式 只是对每一个DSL都从小到大遍历了一次（如果简单枚举的代价主要是验证的话也不是不行 在做）
 5.2对于所有训练问题，保证有一个解（作为num_i即可？） 论文里写的是验证所有解都存在 待确认 
 对于一个DSL和某一个task对应的一些已知解程序，求这些解程序中在DSL程序空间里排序最小的一个规模多大
 读取的task的已知解需要储存（怎么读怎么存），每一个都去贪心match DSL看使用了多少条rule 不如自己重新写这一个功能 不要用istool了 parser可以用
 想在吉老师的代码基础上改发现改不太动所以现在正在重构一下，主要问题现在在define-fun怎么当一个产生式去遍历的？(限制深度的功能限制）
 对所有的task记录对应信息生成对应.sl文件 specification不重要 因为只是想要贪心枚举
 5.3不懂增量式是什么做法 可能可以减量式（对最大的DSL先记录所有的）
 
 __getweight记得return 1











