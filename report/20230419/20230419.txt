泛化实验 1111011101100001011100001001110000 3.75
随机抽取了40个 发现源语言并不完全一样 比如部分case源语言本身没有int.to.str和ite（这会导致eusolver拒绝求解） 或者 有的case是没有ite 而我们特意保留了string和int里的ite（可能会部分变得更复杂）
见excel结果

频繁模式自动化实验 大概完成
------------------------------------------------------------下一段不看
1.所有频繁模式转换成对应的所有可能的完整的树
2.去掉语义等价的树（如str.++不需要生成交换律可以去掉的产生式）
3.对树的距离的刻画 距离小于多少（子串关系）且频繁度下降在多少范围内时选用更精细的case
------------------------------------------------------------下一段不看
1.先对频繁模式做剪枝 如果A是B的频繁模式延伸，且频繁度B>k(=0.8)*频繁度A，则去掉A 76->62
2.对于筛选剩下的频繁模式建树，去掉语义等价的（如交换律 包括与原始相比） 如 1 2 -2160 --> str.substr P0 (P0和一般S的区别在于P0可以获取一些地方参数相同的特征）
 一个频繁模式对应多个树的问题（将完全树的编码返回给频繁模式数据集检验 举例来说 频繁模式 0 0对应的是str.++ str.++，但是0 X... -1 0 和 0 0 -1 X...都会被提取成0 0）
 想要加一个条件叫做频繁模式的相对位置也是给定的（好像一般频繁模式不会满足这一个条件） 相当于把占位符也给到频繁模式里
 目前先 根据每一个频繁模式先建出所有可能的树（然后做 相同语义树的去重？)
 str.++、+、只生成第一个匹配的树（
 
3.额外的知识或者信息利用 如P0大部分都是string 所以str.substr P0 N N 而非str.substr S P0 N 如[['1', '2', '-1', '7', '2'], 418] 表示str.substr P0 str.len(P0) N 或者str.substr P0 N str.len(P0) 利用对str.substr的知识知道后者是合理的 如str.++是交换的 0 ...不需要生成多个树 

提前建立树的节点类型（子节点数目和数据类型）
-------------------------------------------------------------这里开始看
熊老师的建议 可以加入大量expert domain knowledge
最后采取的方案：
1.先对频繁模式做剪枝 如果A是B的频繁模式延伸，且频繁度B>k(=0.8)*频繁度A，则去掉A 76->62
2.采取贪心加expert knowledge的方式给出了每一个频繁模式最可能对应的表达式 最可能对应的意思是：如str.++ S S等只生成一个 如- N 1和 - 1 N之中选择的是前者 如substr 和 len的组合时，len应该出现在后面一个N处
3.进一步挑选 因为有些频繁模式生成的如 str.++ stringconst s 和原始文法没有区别 或者某两个频繁模式实际上等价 （如何在这里做删除 给个标准interpreter直接比较去重？） 62->36（之前手工挑的是15个） 观察了一下13/15是原本有的现在也有的 去除的两个原本也是手动加上去的（str.replace相关 而maxflash给的解一般不用str.replace） 前面的泛化实验也没有采用这两个特别的产生式
 StringConst可以直接替换为S param0除了替换成S1之外要注意出现两次的情况 此外也可以替换成S
4.整理性工作 把最后得到的产生式加入到遗传算法的备选pool里
5.重写 让修改数据集和训练集时候的接口更加general 获取频繁模式自动化，自动获取header，tailer，常量等 如果有别的比如bitvector也需要对应的整个流程


整个流程的梳理：
1.收集某个domian下的一系列问题 对应初始源语言L 划分出一部分训练集S、（测试集P？）验证集R（编码每个问题的函数签名、常量、待满足限制条件，自动化获取这些信息）
2.使用某个求解器或者多个求解器(如maxflash）在训练集S上求解 每个问题期望求解出k=100个可行解，共|S|*k个解作为频繁模式挖掘所用程序
2.5挖掘频繁模式的参数实际上现在并没有标准化定义，在当前实验中是尝试了不同的参数（支持度：可以理解成要求出现多少次以上） 最后采取了400 获得了76个频繁模式
3.对挖掘出来的频繁模式进行refine（去掉冗余、去掉语义相同）得到最后的产生式pool
3.5注意refine需要编写expert interpreter（如要处理bitvector，则挖掘出的频繁模式也需要加工）
4.利用获取的产生式pool和原始文法编码（删除）基因
4.5在当前基因编码下，采样出多个基因，求解出训练集上对应的具体加速比。这个数据用来训练xgboost模型。
4.7对于每一个基因，以其DSL在训练集问题上估算的求解情况作为feature，以真实加速比作为output，feature-output pair作为训练数据。（目前的估算可以理解成简单枚举观察第一个解出现在第几个，针对其他的求解器需要design出不同的feature）
5.通过遗传算法（适应度函数利用某个已有模型如xgboost）在训练集上迭代筛选出表现较好的基因，再细粒度筛选出最后的基因
6.在验证集上检验最后基因的表现 证明确实可以找到更好的文法


TODO：把剩下的没写完的接口补完
按上述框架重构代码和整体框架 （有哪些接口需要留出来方便修改）
重新对于整个String的domain划分一部分训练集和验证机跑一遍整个流程（主要时间代价应该会在训练xgboost上）
对于不同的求解器？或者直接也可以用这样得到的dsl在eusolver上检验（不同feature设计）对于另一个domain如bitvector？


----------------------------------------------------------------------
关于博资考or新研究方向的思考
熊老师描述的初步想法：
1.基于训练好的模型做逆向工程，搞清楚模型是如何工作的
2.利用完整获取的神经网络，假使它确实比较好的模拟了人类神经系统，利用我们对于神经网络的可操作性反推一些关于人类神经系统的有关性质（如基于伦理道德无法对人脑进行的一系列实验）

相关领域：（要写博资考报告）
神经网络解释：解释的目标是一些比较well studied的其他模型 如线性模型、决策树等等，目标是将神经网络的功能表达为这些模型，即解释神经网络=用其他模型表达该神经网络的功能。
模型编辑：icse新文章（和之前的KN模型），对于一个神经网络，在遇到输入输出不符合期望时，通过定位critical neuron，利用已知输入和输出反向推理构造出一个可能期望的中间输出（对于目标神经元）----这一步我还没有完全理解是不是自然可以做到的---，更新神经元的参数使得神经网络的输出更加符合期望。
心理学or脑科学：对于人的心理系统或者大脑功能的认知，比如利用人在处理不同任务时大脑各部分激活状态不同定位出各种如语言分区（理解和表达是不同的区域）、行动分区；（也有一些是利用机缘巧合下得到的某一个区域受损的患者从而发现理解语言和表达语言的分区并不相同）；特殊的违反人伦的实验，大脑部分切除观察表现。
模型切割？？

对于两个问题，期望的结果形式 和 可能的研究方法
对于问题1的期望的结果形式：
a.类似神经网络解释，翻译为某一个general但是可理解的模型，翻译成一个条件和行为都有比较清晰语义的算法（如对于自然语言处理问题） 
人类是如何解决问题的，对于某一个具体问题的解答，往往也就是利用逻辑语言将一些条件判断和运算组合起来 但是这个条件判断应该是有具体语义的
b.结合后续，给出模型每一个部分（如果可以分割）分别在处理怎样的子问题，被加工传递的输入输出是否可以有某种语义上的解释
问题1的可能的研究方法：
神经网络解释是怎么翻译到各个模型的（


对于问题2得到期望的结果：
a.脑科学 认知科学中有哪些受限于科学伦理无法进行的实验？如脑组织切除，这些实验迁移到神经网络模型中会是怎样的表现？如果可以对神经网络给出各种功能分区（怎么给出？），（如解决一些genaral任务的神经网络）通过“切除”部分神经元会对神经网络产生怎样的影响？这个影响是否可以反向类推到人脑？
问题2可能的研究方法：
定位critical neuron？neuron聚类？分区划分？










